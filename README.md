# WORKSHOP: Desenvolvendo Pipelines de Dados Modernos com Apache Airflow | 1º de outubro, às 20h

## Aprendendo:

✅ DAG Skaffold: Como implementar ingestão, processamento, controle de qualidade e entrega de dados.

✅ Estruturação de Projetos: Melhores práticas para organizar e estruturar seus fluxos de trabalho no Airflow.

✅ Reutilização de Código: Técnicas para criar workflows modulares e reutilizáveis.

✅ Data Quality: Como garantir a qualidade dos dados em todos os estágios do pipeline.

✅ Dynamic Task Mapping: Automatização avançada para criar tarefas dinâmicas em seus DAGs.

✅ Isolamento e Pools: Controle de recursos para melhorar o desempenho.

✅ Setup & Teardown Tasks: Automação para preparar e limpar ambientes no início e fim das execuções.

✅ AOK (Airflow on Kubernetes): Como escalar seus pipelines utilizando o Kubernetes.
